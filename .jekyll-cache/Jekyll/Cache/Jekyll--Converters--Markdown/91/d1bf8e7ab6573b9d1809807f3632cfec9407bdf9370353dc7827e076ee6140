I"!<h1 id="从零开始的深度学习-序">从零开始的深度学习: 序</h1>

<p>本系列博文为笔者基于《深度学习入门: 基于Python的理论与实现》, 结合个人思考和扩展阅读而成的读书笔记, 内容安排上因笔者具备的背景知识范围和兴趣而与原书有一定差别.</p>

<p>系列博文的具体结构如下:</p>

<h2 id="ch1-感知机-perceptron-与神经网络的定义-实现和扩展"><code class="language-plaintext highlighter-rouge">Ch1</code>: 感知机 <code class="language-plaintext highlighter-rouge">Perceptron</code> 与神经网络的定义, 实现和扩展<br /></h2>
<h3 id="1-感知机的定义">1. 感知机的定义</h3>
<h3 id="2-感知机的局限性和扩展的多层感知机-以异或门电路的实现为例">2. 感知机的局限性和扩展的多层感知机: 以异或门电路的实现为例</h3>
<h3 id="3-神经网络的定义和层级结构">3. 神经网络的定义和层级结构</h3>
<h3 id="4-激活函数的定义和常见的激活函数">4. 激活函数的定义和常见的激活函数</h3>
<h3 id="5-三层神经网络的实现">5. 三层神经网络的实现</h3>
<h3 id="6-神经网络的输出">6. 神经网络的输出</h3>

<p><br /></p>

<h2 id="ch2-神经网络的学习-损失函数和梯度下降法"><code class="language-plaintext highlighter-rouge">Ch2</code>: 神经网络的学习: 损失函数和梯度下降法<br /></h2>
<h3 id="1-基本定义和术语">1. 基本定义和术语</h3>
<h3 id="2-损失函数和小批量学习法">2. 损失函数和小批量学习法</h3>
<h3 id="3-数值微分和梯度下降法">3. 数值微分和梯度下降法</h3>
<h3 id="4-随机梯度下降法的实现">4. 随机梯度下降法的实现</h3>

<p><br /></p>

<h2 id="ch3-神经网络的优化-误差反向传播法"><code class="language-plaintext highlighter-rouge">Ch3</code>: 神经网络的优化: 误差反向传播法<br /></h2>
<h3 id="1-链式法则和反向传播">1. 链式法则和反向传播</h3>
<h3 id="2-乘法层和加法层的实现">2. 乘法层和加法层的实现</h3>
<h3 id="3-激活函数层的实现">3. 激活函数层的实现</h3>
<h3 id="4-affinesoftmax-层的实现">4. <code class="language-plaintext highlighter-rouge">Affine/SoftMax</code> 层的实现</h3>
<h3 id="5-误差反向传播法的实现">5. 误差反向传播法的实现</h3>

<p><br /></p>

<h2 id="ch4-神经网络优化算法技巧"><code class="language-plaintext highlighter-rouge">Ch4</code>: 神经网络优化算法技巧</h2>
<h3 id="1-随机梯度下降法-sgd">1. 随机梯度下降法 <code class="language-plaintext highlighter-rouge">SGD</code></h3>
<h3 id="2-动量方法-momentum">2. 动量方法 <code class="language-plaintext highlighter-rouge">Momentum</code></h3>
<h3 id="3-自适应梯度法-adagrad">3. 自适应梯度法 <code class="language-plaintext highlighter-rouge">AdaGrad</code></h3>
<h3 id="4-adam-算法">4. <code class="language-plaintext highlighter-rouge">Adam</code> 算法</h3>
<h3 id="5-批量归一化-batch-normalization">5. 批量归一化 <code class="language-plaintext highlighter-rouge">Batch Normalization</code></h3>
<h3 id="6-抑制过拟合-正则化">6. 抑制过拟合: 正则化</h3>

<p><br /></p>

<h2 id="ch5-卷积神经网络"><code class="language-plaintext highlighter-rouge">Ch5</code>: 卷积神经网络<br /></h2>
<h3 id="1-卷积层和池化层">1. 卷积层和池化层</h3>
<h3 id="2-卷积层与池化层的实现">2. 卷积层与池化层的实现</h3>
<h3 id="3-卷积神经网络的实现和可视化">3. 卷积神经网络的实现和可视化</h3>
:ET