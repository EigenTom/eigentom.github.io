<!DOCTYPE html>
<html lang="en">


<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">
    <meta name="description" content="由于相关法律法规规定, 该内容无法显示.">
    <meta name="keywords" content="菜">
    <meta name="theme-color" content="#333">

    <!-- Open Graph -->
    <meta property="og:title"
        content="从零开始的深度学习 Ch4 - 某一般线性空间 | Ramdom Linear Space">
    
    <meta property="og:type" content="article">
    <meta property="og:description" content="神经网络优化算法技巧
在前一章的介绍中, 我们已经明白, 神经网络学习的本质是一个优化问题: 通过多轮迭代对参数进行最优化, 从而使得损失函数的值尽可能的小. 和普通的最优化问题不同, 神经网络的最优化问题涉及的参数空间复杂, 无法使用解析的方式求得最优解, 而在深度神经网络中, 参数的规模则更加庞大.
">
    
    <meta property="article:published_time" content=" 2021-01-09T00:00:00Z">
    
    
    <meta property="article:author" content="R1NG">
    
    
    <meta property="article:tag" content="扩展自习">
    
    <meta property="article:tag" content="机器学习">
    
    
    <meta property="og:image" content="http://localhost:4000https://github.com/KirisameR.png">
    <meta property="og:url" content="http://localhost:4000/2021/01/09/Ch4-DeepLearningNotes/">
    <meta property="og:site_name" content="某一般线性空间 | Ramdom Linear Space">

    <title>从零开始的深度学习 Ch4 - 某一般线性空间 | Ramdom Linear Space</title>

    <!-- Web App Manifest -->
    <link rel="manifest" href="/pwa/manifest.json">

    <!-- Favicon -->
    <link rel="shortcut icon" href="/img/favicon.ico">

    <!-- Canonical URL -->
    <link rel="canonical" href="http://localhost:4000/2021/01/09/Ch4-DeepLearningNotes/">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href=" /css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href=" /css/hux-blog.min.css">
    
    <!-- Local Dev Debugging
    <link rel="stylesheet" href=" /css/font-awesome.min.css"> 
    -->
    

    <!-- Custom Fonts -->
    <!-- <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    <!-- Hux change font-awesome CDN to qiniu -->
    <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet"type="text/css">
    <!-- Add Parallex Effect-->
    <script src="/js/jquery.min.js "></script>
    <script src="/js/rellax.min.js"></script>


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- ga & ba script hoook -->
    <script></script>

    <!-- 数学公式 -->
    <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-MML-AM_CHTML"></script>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
            showProcessingMessages: true, //关闭js加载过程信息
            messageStyle: "none", //不显示信息
            extensions: ["tex2jax.js"],
            jax: ["input/TeX", "output/HTML-CSS"],
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code','a'], //避开某些标签
                ignoreClass:"comment-content" //避开含该Class的标签
            },
            "HTML-CSS": {
                availableFonts: ["STIX","TeX"], //可选字体
                showMathMenu: false //关闭右击菜单显示
            }
        });
        MathJax.Hub.Queue(["Typeset",MathJax.Hub]);
    </script>

    

    <!-- Google AdSense -->
    <script data-ad-client="ca-pub-6487568398225121" async
        src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
</head>



<!-- hack iOS CSS :active style -->
<body ontouchstart="">
    <!-- Search -->
<div class="search-page">
  <div class="search-icon-close-container">
    <span class="search-icon-close">
      <i class="fa fa-times"></i>
    </span>
  </div>
  <div class="search-main container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <form></form>
        <input type="text" id="search-input" placeholder="$ grep...">
        </form>
        <div id="search-results" class="mini-post-list"></div>
      </div>
    </div>
  </div>
</div>
    
<div class="floatbtn" onclick="document.getElementsByClassName('wrapper')[0].scrollTop = 0">
    <i class="fa fa-arrow-up"></i>
</div>




    
    <!-- Navigation -->

    <nav class="navbar navbar-default navbar-custom navbar-fixed-top">
        
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="/">RANDOM LINEAR SPACE</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div id="huxblog_navbar">
                <div class="navbar-collapse">
                    <ul class="nav navbar-nav navbar-right">
                        <li>
                            <a href="/">Home</a>
                        </li>
                        
                        
                        
                        
                        <li>
                            <a href="/about/">About</a>
                        </li>
                        
                        
                        
                        <li>
                            <a href="/archive/">Archive</a>
                        </li>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <li class="search-icon">
                            <a href="javascript:void(0)">
                                <i class="fa fa-search"></i>
                            </a>
                        </li>
                    </ul>
                </div>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    <script>
        // Drop Bootstarp low-performance Navbar
        // Use customize navbar with high-quality material design animation
        // in high-perf jank-free CSS3 implementation
        var $body = document.body;
        var $toggle = document.querySelector('.navbar-toggle');
        var $navbar = document.querySelector('#huxblog_navbar');
        var $collapse = document.querySelector('.navbar-collapse');

        var __HuxNav__ = {
            close: function () {
                $navbar.className = " ";
                // wait until animation end.
                setTimeout(function () {
                    // prevent frequently toggle
                    if ($navbar.className.indexOf('in') < 0) {
                        $collapse.style.height = "0px"
                    }
                }, 400)
            },
            open: function () {
                $collapse.style.height = "auto"
                $navbar.className += " in";
            }
        }

        // Bind Event
        $toggle.addEventListener('click', function (e) {
            if ($navbar.className.indexOf('in') > 0) {
                __HuxNav__.close()
            } else {
                __HuxNav__.open()
            }
        })

        /**
         * Since Fastclick is used to delegate 'touchstart' globally
         * to hack 300ms delay in iOS by performing a fake 'click',
         * Using 'e.stopPropagation' to stop 'touchstart' event from 
         * $toggle/$collapse will break global delegation.
         * 
         * Instead, we use a 'e.target' filter to prevent handler
         * added to document close HuxNav.  
         *
         * Also, we use 'click' instead of 'touchstart' as compromise
         */
        document.addEventListener('click', function (e) {
            if (e.target == $toggle) return;
            if (e.target.className == 'icon-bar') return;
            __HuxNav__.close();
        })
    </script>
    <!-- Image to hack wechat -->
<!-- <img src="/img/icon_wechat.png" width="0" height="0"> -->
<!-- <img src="/img/post-bg-deeplearning.jpg" width="0" height="0"> -->


<!-- Post Header -->



<style type="text/css">
    header.intro-header{
        position: relative;
    }

    
</style>

<header class="intro-header" >


    <img src="/img/post-bg-deeplearning.jpg" class="bg-image"> 

    
    
    <div class="header-mask"></div>
    
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                        <a class="tag" href="/archive/?tag=%E6%89%A9%E5%B1%95%E8%87%AA%E4%B9%A0" title="扩展自习">扩展自习</a>
                        
                        <a class="tag" href="/archive/?tag=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0" title="机器学习">机器学习</a>
                        
                    </div>
                    <h1>从零开始的深度学习 Ch4</h1>
                    
                    <h2 class="subheading">Introducing numerous optimization methods for better neural network performance</h2>
                    <span class="meta">Posted by R1NG on January 9, 2021</span>

                    
                    <span class="meta" id="busuanzi_container_site_pv">Viewed <b style="color: var(--sidebar-main-color); background-color: transparent !important; font-style: bold;"><i><span id="busuanzi_value_site_pv"><i class="fa fa-spinner fa-spin"></i></span></i></b> Times</span>
                    
                </div>
            </div>
        </div>
    </div>
</header>






<div class="main-container">
<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

    <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                <!-- Multi-Lingual -->
                

				<h1 id="神经网络优化算法技巧">神经网络优化算法技巧</h1>
<p>在前一章的介绍中, 我们已经明白, 神经网络学习的本质是一个优化问题: 通过多轮迭代对参数进行最优化, 从而使得损失函数的值尽可能的小. 和普通的最优化问题不同, 神经网络的最优化问题涉及的参数空间复杂, 无法使用解析的方式求得最优解, 而在深度神经网络中, 参数的规模则更加庞大.</p>

<p>上一章中, 我们简述了随机梯度下降法作为神经网络训练过程中的参数优化方法. 在本节中, 我们将继续介绍其余几种更复杂, 性能更好的参数优化方法.</p>

<p><br /></p>

<h2 id="1-随机梯度下降法-sgd">1. 随机梯度下降法 <code class="language-plaintext highlighter-rouge">SGD</code></h2>

<p>随机梯度下降法在上一章中已经简要介绍. 在介绍新方法之前, 我们先简要回顾一下:</p>

<p><code class="language-plaintext highlighter-rouge">SGD</code> 的核心原理如下式所示:</p>

\[W \leftarrow W - \eta \frac{\partial{L}}{\partial{W}}\]

<p>此处, $W$ 为待更新的权重参数, $\eta$ 为每一次更新所执行的优化步长 (学习率), $\frac{\partial{L}}{\partial{W}}$ 为损失函数 $L$ 关于 $W$ 的偏导数.</p>

<p>其 <code class="language-plaintext highlighter-rouge">Python</code> 实现如下:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre></td><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">SGD</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
    
    <span class="c1"># lr: learning rate, set to 0.01 here as an example
</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
    
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">params</span><span class="p">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">-=</span> <span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">*</span> <span class="n">grads</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">SGD</code> 的优化思想很简单: 始终认为梯度指向极值, 按照它的方向不断行进, 最后就会到达极值处. 而当函数的梯度并不和假设一样指向极值时, 其效率就会明显下降. 考虑一个曲面或超曲面, 使用 <code class="language-plaintext highlighter-rouge">SGD</code> 方法求其最低点时, 极有可能陷入曲面的鞍点处而难以逃脱:</p>

<p><img src="https://cdn.jsdelivr.net/gh/KirisameMarisaa/KirisameMarisaa.github.io/img/blogpost_images/20210128224300.png" alt="20210128224300" /></p>

<p>下面, 我们介绍几个更优化的方法.</p>

<p><br /></p>

<h2 id="2-动量方法-momentum">2. 动量方法 <code class="language-plaintext highlighter-rouge">Momentum</code></h2>

<p>动量方法是物理模型和数学意义的结合, 它将参数进行最优化的过程假定为参数取值点在高低不一的平面或超平面上运动的过程, 引入了 “动量“ 的概念, 这与其名称对应. 其核心原理如下式所示:</p>

\[v \leftarrow \alpha v - \eta \frac{\partial{L}}{\partial{W}}\]

\[W \leftarrow W + v\]

<p>此处出现的新变量 $v$ 对应物体运动的速度, $\alpha$ 对应和运动方向相反的摩擦阻力, 而 $\alpha v$ 即为动量的改变量. 在动量方法的优化过程中, 参数取值点除了会逐渐向梯度所指向的方向移动外, 其来回往复的运动行为会被抑制, 而单向的运动行为会被强化, 由此可以更快地从鞍点处逃逸.</p>

<p>其 <code class="language-plaintext highlighter-rouge">Python</code> 实现如下:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre></td><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">Momentum</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">momentum</span> <span class="o">=</span> <span class="n">momentum</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">v</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>

        <span class="c1"># initialize at the begining
</span>        <span class="c1"># store the velocity of each params, encode as a dict
</span>    
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">v</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">v</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">params</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">params</span><span class="p">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">momentum</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">*</span> <span class="n">grads</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            <span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><br /></p>

<h2 id="3-自适应梯度法-adagrad">3. 自适应梯度法 <code class="language-plaintext highlighter-rouge">AdaGrad</code></h2>

<p>自适应梯度法会在学习过程中为每一个参数适当调节其学习率. 其核心原理如下:</p>

\[h \leftarrow h + \frac{\partial{L}}{\partial{W}} \otimes \frac{\partial{L}}{\partial{W}}\]

\[W \leftarrow W - \eta \frac{1}{\sqrt{h}}\frac{\partial{L}}{\partial{W}}\]

<p>此处的 $\otimes$ 是 <strong>矩阵乘法</strong>, 变量 $h$ 保存了对参数 $W$ 而言的, 此前学习中所有梯度的平方和. 通过在每一次更新时对学习率乘以不断减小的权值 $\frac{1}{\sqrt{h}}$, 可使学习的尺度随着学习周期的增加而减小, 从而实现学习率的衰减.</p>

<p>其 <code class="language-plaintext highlighter-rouge">Python</code> 实现如下:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">AdaGrad</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">h</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">h</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">h</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">params</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">h</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">params</span><span class="p">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">h</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+=</span> <span class="n">grads</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">*</span> <span class="n">grads</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            <span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">-=</span> <span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">*</span> <span class="n">grads</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">h</span><span class="p">[</span><span class="n">key</span><span class="p">])</span> <span class="o">+</span> <span class="mf">1e-7</span><span class="p">)</span>

            <span class="c1"># plus a small num incase overflow
</span></pre></td></tr></tbody></table></code></pre></div></div>

<p><br /></p>

<h2 id="4-adam-算法">4. <code class="language-plaintext highlighter-rouge">Adam</code> 算法</h2>

<p><code class="language-plaintext highlighter-rouge">Adam</code> 方法基本可以视为前两种方法的结合, 在此不作详细介绍.</p>

<p><br /></p>

<h2 id="5-批量归一化-batch-normalization">5. 批量归一化 <code class="language-plaintext highlighter-rouge">Batch Normalization</code></h2>

<p>批标准化方法的目的是强制调整神经网络激活值的分布, 从而使各层拥有适当的广度. 它拥有增大学习率, 对初始值依赖程度低, 和可抑制过拟合的特性.</p>

<p>在使用批标准化方法时, 需要向神经网络中插入对数据分布进行正规化的层 (<code class="language-plaintext highlighter-rouge">Batch Normalization</code>), 从而实现对激活值的调整.</p>

<p><code class="language-plaintext highlighter-rouge">Batch Normalization</code> 就是以进行学习时的 <code class="language-plaintext highlighter-rouge">mini-batch</code> 为基本单位, 进行使数据分布的均值为 $0$, 方差为 $1$ 的正规化. 设被正规化的输入数据的集合为 ${x_1, x_2, \cdots, x_m}$, 则有:</p>

\[\mu_{B} \leftarrow \frac{1}{m} \sum_{i=1}^{m}x_{i}\]

\[\sigma^{2}_{B} \leftarrow \frac{1}{m} \sum_{i=1}^{m}(x_{i} - \mu_{B})^{2}\]

\[\hat{x_{i}} \leftarrow \frac{x_{i} - \mu_{B}}{\sqrt{\sigma_{B}^{2} + \epsilon}}\]

<p>注: $\epsilon$ 为一个极小值, 其意义在于防止分母为 $0$ 的情况发生.</p>

<p>上述三式将输入数据集 ${x_1, x_2, \cdots, x_m}$ 转换为均值为 $0$, 方差为 $1$ 的数据集 ${\hat{x}_1, \hat{x}_2, \cdots, \hat{x}_m}$. 通过将该处理插入到激活函数层前或后面, 可以减小数据分布的偏向.</p>

<p>随后, <code class="language-plaintext highlighter-rouge">Batch Normalization</code> 层还会对经过正规化后的数据集 ${\hat{x}_1, \hat{x}_2, \cdots, \hat{x}_m}$ 作仿射变换:</p>

\[y_{i} \leftarrow \gamma\hat{x}_i + \beta\]

<p>此处 $\gamma, \beta$ 为参数, 初始值分别为 $1, 0$, 在学习过程中参数值会被调整.</p>

<p><br /></p>

<h2 id="6-抑制过拟合-正则化">6. 抑制过拟合: 正则化</h2>

<p>发生过拟合的原因主要有两个: 模型拥有大量参数 (神经网络规模大), 和训练数据不足.</p>

<p>一种普遍被用于抑制过拟合的方法是 <strong>权值衰减</strong>. 它通过在学习的过程中对取值较大的权重进行 “惩罚” 来抑制过拟合. 一种常见的过拟合抑制方法是: 为损失函数加上权重的 $L2$ 范数 (平方范数), 即可抑制权重变大.</p>

<p>[注] $L2$ 范数是各个元素的平方和.</p>

<p>除了为损失函数加上 $L2$ 范数的权值衰减方法外, 还有一种方法可以应对复杂网络模型的过拟合抑制, 这就是 <code class="language-plaintext highlighter-rouge">Dropout</code> 方法.</p>

<p>复杂网络模型中神经元数量众多, <code class="language-plaintext highlighter-rouge">Dropout</code> 方法会在学习的过程中随机删除神经元. 在训练时, 随机选出隐藏层的神经元并将其删除, 被删除的神经元不再进行信号的传递.</p>

<p><img src="https://cdn.jsdelivr.net/gh/KirisameMarisaa/KirisameMarisaa.github.io/img/blogpost_images/20210130214913.png" alt="20210130214913" /></p>

<p><br /></p>


                <hr style="visibility: hidden;">
                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/2021/01/09/Ch3-DeepLearningNotes/" data-toggle="tooltip" data-placement="top" title="从零开始的深度学习 Ch3">
                        Previous<br>
                        <span>从零开始的深度学习 Ch3</span>
                        </a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/2021/01/10/Ch5-DeepLearningNotes/" data-toggle="tooltip" data-placement="top" title="从零开始的深度学习 Ch5">
                        Next<br>
                        <span>从零开始的深度学习 Ch5</span>
                        </a>
                    </li>
                    
                </ul>
                <hr style="visibility: hidden;">

                
                <!-- disqus 评论框 start -->
                <div class="comment">
                    <div id="disqus_thread" class="disqus-thread"></div>
                </div>
                <!-- disqus 评论框 end -->
                

                
            </div>  

    <!-- Side Catalog Container -->
        
            <div class="
                col-lg-2 col-lg-offset-0
                visible-lg-block
                sidebar-container
                catalog-container">
                <div class="side-catalog">
                    <hr class="hidden-sm hidden-xs">
                    <h5>
                        <a class="catalog-toggle" href="#">CATALOG</a>
                    </h5>
                    <ul class="catalog-body"></ul>
                </div>
            </div>
        

    <!-- Sidebar Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                


<section>
    
        <hr class="hidden-sm hidden-xs">
    
    <h5><a href="/archive/">FEATURED TAGS</a></h5>
    <div class="tags">
        
        
        
        
        
        
                <a data-sort="0126" 
                    href="/archive/?tag=COMP12111"
                    title="COMP12111"
                    rel="10">COMP12111</a>
        
                <a data-sort="0072" 
                    href="/archive/?tag=%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0"
                    title="课程笔记"
                    rel="64">课程笔记</a>
        
                <a data-sort="0096" 
                    href="/archive/?tag=%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0"
                    title="前端学习"
                    rel="40">前端学习</a>
        
                <a data-sort="0096" 
                    href="/archive/?tag=50P50D"
                    title="50P50D"
                    rel="40">50P50D</a>
        
                <a data-sort="0123" 
                    href="/archive/?tag=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD"
                    title="人工智能"
                    rel="13">人工智能</a>
        
                <a data-sort="0124" 
                    href="/archive/?tag=%E9%80%BB%E8%BE%91%E5%AD%A6"
                    title="逻辑学"
                    rel="12">逻辑学</a>
        
                <a data-sort="0126" 
                    href="/archive/?tag=COMP15111"
                    title="COMP15111"
                    rel="10">COMP15111</a>
        
                <a data-sort="0127" 
                    href="/archive/?tag=%E6%89%A9%E5%B1%95%E8%87%AA%E4%B9%A0"
                    title="扩展自习"
                    rel="9">扩展自习</a>
        
                <a data-sort="0127" 
                    href="/archive/?tag=COMP21111"
                    title="COMP21111"
                    rel="9">COMP21111</a>
        
                <a data-sort="0129" 
                    href="/archive/?tag=%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95"
                    title="数据结构与算法"
                    rel="7">数据结构与算法</a>
        
                <a data-sort="0129" 
                    href="/archive/?tag=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"
                    title="机器学习"
                    rel="7">机器学习</a>
        
                <a data-sort="0129" 
                    href="/archive/?tag=COMP11212"
                    title="COMP11212"
                    rel="7">COMP11212</a>
        
                <a data-sort="0130" 
                    href="/archive/?tag=COMP24011"
                    title="COMP24011"
                    rel="6">COMP24011</a>
        
                <a data-sort="0132" 
                    href="/archive/?tag=%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AF%BC%E8%AE%BA"
                    title="数据库导论"
                    rel="4">数据库导论</a>
        
                <a data-sort="0132" 
                    href="/archive/?tag=%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95"
                    title="数据结构和算法"
                    rel="4">数据结构和算法</a>
        
                <a data-sort="0132" 
                    href="/archive/?tag=COMP15212"
                    title="COMP15212"
                    rel="4">COMP15212</a>
        
                <a data-sort="0134" 
                    href="/archive/?tag=%E5%A5%87%E6%8A%80%E6%B7%AB%E5%B7%A7"
                    title="奇技淫巧"
                    rel="2">奇技淫巧</a>
        
                <a data-sort="0134" 
                    href="/archive/?tag=%E7%AE%97%E6%B3%95"
                    title="算法"
                    rel="2">算法</a>
        
                <a data-sort="0134" 
                    href="/archive/?tag=%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6"
                    title="计算机图形学"
                    rel="2">计算机图形学</a>
        
                <a data-sort="0134" 
                    href="/archive/?tag=%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E6%A6%82%E8%AE%BA"
                    title="软件工程概论"
                    rel="2">软件工程概论</a>
        
                <a data-sort="0134" 
                    href="/archive/?tag=Lab"
                    title="Lab"
                    rel="2">Lab</a>
    </div>
</section>


                <!-- Friends Blog -->
                
<hr>
<h5>FRIENDS</h5>
<ul class="list-inline">
  
  <li><a href="http://ryanxin.cn">琳若尘泥 十里琅居</a></li>
  
  <li><a href="https://flyhigher.top">无垠 - 飞翔的天空无限大</a></li>
  
  <li><a href="https://graynekocafe.net">灰貓咖啡廳</a></li>
  
  <li><a href="Gnefil.github.io">GNEFIL</a></li>
  
</ul>

            </div>
        </div>
    </div>
</article>

</div>


<!-- add support for mathjax by voleking-->


<!-- add busuanzi statistics support-->
    
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>






<!-- disqus 公共JS代码 start (一个网页只需插入一次) -->
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES * * */
    var disqus_shortname = "KirisameR";
    var disqus_identifier = "/2021/01/09/Ch4 DeepLearningNotes";
    var disqus_url = "http://localhost:4000/2021/01/09/Ch4-DeepLearningNotes/";

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<!-- disqus 公共JS代码 end -->




<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>
<!-- anchor-js, Doc:http://bryanbraun.github.io/anchorjs/ -->
<script>
    async("//cdnjs.cloudflare.com/ajax/libs/anchor-js/1.1.1/anchor.min.js",function(){
        anchors.options = {
          visible: 'hover',
          placement: 'right',
          // icon: '#'
        };
        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
    })
</script>
<style>
    /* place left on bigger screen */
    @media all and (min-width: 800px) {
        .anchorjs-link{
            position: absolute;
            left: -0.75em;
            font-size: 1.1em;
            margin-top : -0.1em;
        }
    }
</style>

    
    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <!-- SNS Link -->
                


<ul class="list-inline text-center">


  
  
  <li>
    <a href="https://twitter.com/eigentom">
      <span class="fa-stack fa-lg">
        <i class="fa fa-circle fa-stack-2x"></i>
        <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
      </span>
    </a>
  </li>
  
  
  
  <li>
    <a target="_blank" href="http://t.me/Kirisame_Marisa">
      <span class="fa-stack fa-lg">
        <i class="fa fa-circle fa-stack-2x"></i>
        <i class="fa fa-telegram fa-stack-1x fa-inverse"></i>
      </span>
    </a>
  </li>
  
  
  
  <li>
    <a target="_blank" href="https://github.com/KirisameR">
      <span class="fa-stack fa-lg">
        <i class="fa fa-circle fa-stack-2x"></i>
        <i class="fa fa-github fa-stack-1x fa-inverse"></i>
      </span>
    </a>
  </li>
  
  
  <li>
    <a target="_blank" href="https://www.linkedin.com/in/yilu-82589933">
      <span class="fa-stack fa-lg">
        <i class="fa fa-circle fa-stack-2x"></i>
        <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
      </span>
    </a>
  </li>
  
</ul>

                <p class="copyright text-muted">
                    Copyright &copy; 某一般线性空间 2022
                    <br>
                    Powered by <a href="616.sb">Hux Enhanced</a> |
                    <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="100px"
                        height="20px"
                        src="https://ghbtns.com/github-btn.html?user=huxpro&repo=huxpro.github.io&type=star&count=true">
                    </iframe>
                </p>
            </div>
        </div>
    </div>
</footer>


<!-- jQuery -->
<script src="/js/jquery.min.js "></script>

<!-- Bootstrap Core JavaScript -->
<!-- Currently, only navbar scroll-down effect at desktop still depends on this -->
<script src="/js/bootstrap.min.js "></script>

<!-- Custom Theme JavaScript -->
<script src="/js/hux-blog.min.js "></script>

<!-- Simple Jekyll Search -->
<script src="/js/simple-jekyll-search.min.js"></script>

<!-- Service Worker -->

<script src="/js/snackbar.js "></script>
<script src="/js/sw-registration.js "></script>


<!-- async load function -->
<script>
    function async(u, c) {
        var d = document, t = 'script',
            o = d.createElement(t),
            s = d.getElementsByTagName(t)[0];
        o.src = u;
        if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
        s.parentNode.insertBefore(o, s);
    }
</script>

<!--
     Because of the native support for backtick-style fenced code blocks
     right within the Markdown is landed in Github Pages,
     From V1.6, There is no need for Highlight.js,
     so Huxblog drops it officially.

     - https://github.com/blog/2100-github-pages-now-faster-and-simpler-with-jekyll-3-0
     - https://help.github.com/articles/creating-and-highlighting-code-blocks/
     - https://github.com/jneen/rouge/wiki/list-of-supported-languages-and-lexers
-->
<!--
    <script>
        async("http://cdn.bootcss.com/highlight.js/8.6/highlight.min.js", function(){
            hljs.initHighlightingOnLoad();
        })
    </script>
    <link href="http://cdn.bootcss.com/highlight.js/8.6/styles/github.min.css" rel="stylesheet">
-->







<!--fastClick.js -->
<script>
    async("//cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.min.js", function () {
        var $nav = document.querySelector("nav");
        if ($nav) FastClick.attach($nav);
    })
</script>


<!-- Google Analytics -->



<!-- Baidu Tongji -->



<!-- Side Catalog -->

<script type="text/javascript">
    function generateCatalog(selector) {

        // interop with multilangual 
        if ('' == 'true') {
            _containerSelector = 'div.post-container.active'
        } else {
            _containerSelector = 'div.post-container'
        }

        // init
        var P = $(_containerSelector), a, n, t, l, i, c;
        a = P.find('h1,h2,h3,h4,h5,h6');

        // clean
        $(selector).html('')

        // appending
        a.each(function () {
            n = $(this).prop('tagName').toLowerCase();
            i = "#" + $(this).prop('id');
            t = $(this).text();
            c = $('<a href="' + i + '" rel="nofollow">' + t + '</a>');
            l = $('<li class="' + n + '_nav"></li>').append(c);
            $(selector).append(l);
        });
        return true;
    }

    generateCatalog(".catalog-body");

    // toggle side catalog
    $(".catalog-toggle").click((function (e) {
        e.preventDefault();
        $('.side-catalog').toggleClass("fold")
    }))

    /*
     * Doc: https://github.com/davist11/jQuery-One-Page-Nav
     * Fork by Hux to support padding
     */
    async("/js/jquery.nav.js", function () {
        $('.catalog-body').onePageNav({
            currentClass: "active",
            changeHash: !1,
            easing: "swing",
            filter: "",
            scrollSpeed: 700,
            scrollOffset: 0,
            scrollThreshold: .2,
            begin: null,
            end: null,
            scrollChange: null,
            padding: 80
        });
    });
</script>



<!-- Multi-Lingual -->


<!-- Simple Jekyll Search -->
<script>
    // https://stackoverflow.com/questions/1912501/unescape-html-entities-in-javascript
    function htmlDecode(input) {
        var e = document.createElement('textarea');
        e.innerHTML = input;
        // handle case of empty input
        return e.childNodes.length === 0 ? "" : e.childNodes[0].nodeValue;
    }

    SimpleJekyllSearch({
        searchInput: document.getElementById('search-input'),
        resultsContainer: document.getElementById('search-results'),
        json: '/search.json',
        searchResultTemplate: '<div class="post-preview item"><a href="{url}"><h2 class="post-title">{title}</h2><h3 class="post-subtitle">{subtitle}</h3><hr></a></div>',
        noResultsText: 'No results',
        limit: 50,
        fuzzy: false,
        // a hack to get escaped subtitle unescaped. for some reason, 
        // post.subtitle w/o escape filter nuke entire search.
        templateMiddleware: function (prop, value, template) {
            if (prop === 'subtitle' || prop === 'title') {
                if (value.indexOf("code")) {
                    return htmlDecode(value);
                } else {
                    return value;
                }
            }
        }
    });

    $(document).ready(function () {
        var $searchPage = $('.search-page');
        var $searchOpen = $('.search-icon');
        var $searchClose = $('.search-icon-close');
        var $searchInput = $('#search-input');
        var $body = $('body');

        $searchOpen.on('click', function (e) {
            e.preventDefault();
            $searchPage.toggleClass('search-active');
            var prevClasses = $body.attr('class') || '';
            setTimeout(function () {
                $body.addClass('no-scroll');
            }, 400)

            if ($searchPage.hasClass('search-active')) {
                $searchClose.on('click', function (e) {
                    e.preventDefault();
                    $searchPage.removeClass('search-active');
                    $body.attr('class', prevClasses);  // from closure 
                });
                $searchInput.focus();
            }
        });
    });
</script>
    <!-- Image to hack wechat -->
    <img src="/img/icon_wechat.png" width="0" height="0" />
    <!-- Migrate from head to bottom, no longer block render and still work -->
    
</body>

</html>
