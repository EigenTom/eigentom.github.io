---
layout:     post
title:      从零开始的深度学习 Ch0
subtitle:   Let's dive in!
date:       2021-01-07
author:     R1NG
header-img: img/post-bg-deeplearning.jpg
description: 行而上学, 不行退学
catalog: true
tags:
    - 扩展自习
    - 机器学习
---

# 从零开始的深度学习: 序

本系列博文为笔者基于《深度学习入门: 基于Python的理论与实现》, 结合个人思考和扩展阅读而成的读书笔记, 内容安排上因笔者具备的背景知识范围和兴趣而与原书有一定差别. 

系列博文的具体结构如下:

## `Ch1`: 感知机 `Perceptron` 与神经网络的定义, 实现和扩展<br>
### 1. 感知机的定义
### 2. 感知机的局限性和扩展的多层感知机: 以异或门电路的实现为例
### 3. 神经网络的定义和层级结构
### 4. 激活函数的定义和常见的激活函数
### 5. 三层神经网络的实现
### 6. 神经网络的输出

<br>

## `Ch2`: 神经网络的学习: 损失函数和梯度下降法<br>
### 1. 基本定义和术语
### 2. 损失函数和小批量学习法
### 3. 数值微分和梯度下降法
### 4. 随机梯度下降法的实现

<br>

## `Ch3`: 神经网络的优化: 误差反向传播法<br>
### 1. 链式法则和反向传播
### 2. 乘法层和加法层的实现
### 3. 激活函数层的实现
### 4. `Affine/SoftMax` 层的实现
### 5. 误差反向传播法的实现

<br>

## `Ch4`: 神经网络优化算法技巧
### 1. 随机梯度下降法 `SGD`
### 2. 动量方法 `Momentum`
### 3. 自适应梯度法 `AdaGrad`
### 4. `Adam` 算法
### 5. 批量归一化 `Batch Normalization`
### 6. 抑制过拟合: 正则化

<br>

## `Ch5`: 卷积神经网络<br>
### 1. 卷积层和池化层
### 2. 卷积层与池化层的实现
### 3. 卷积神经网络的实现和可视化
