---
layout:     post
title:      人工智能导论 基础搜索算法
subtitle:   Basic Search Algorithms
date:       2021-11-04
author:     R1NG
header-img: img/post-bg-prolog.jpg
description: 本章将介绍数种基础的搜索算法. 
catalog: true
tags:
    - 2021
    - 课程笔记
    - COMP24011
---

# 基础搜索算法

在本章中, 我们首先会对 **推断** 这一逻辑过程进行建模, 并将其含义与 **搜索** 整合起来, 解释 **将推断的逻辑行为建模和实现为搜索算法** 的原理与合理性. 

其次, 我们将介绍包括深度优先搜索 (`DFS`) 在内的数种基础搜索算法. 

## 1. 推断和搜索

下面我们通过一个例子来形象化地理解对问题的建模. 考虑如下的一个问题:

(插图)

给定如上图所示的初始条件, 我们需要生成一系列由 `Dalek` 所执行的操作组成的策略, 从而使得书架被运到客厅 (`sitting room`), 且 `Dalek` 最终位于大厅 (`hall`) 内. 

我们可以如下分别表达这个问题所描述的两种事实:

~~~
// Fluents
[in(dalek, hall), 
 in(bookcase, hall), 
 in(table, study)]

// Permanents
[adjacent(bedroom, hall)
 adjacent(hall, sitting-room), 
 adjacent(sitting-room, study)]
~~~

并且我们可以将问题的目标描述如下:

~~~
// Goals
[in(dalek, hall), in(table, sitting-room)]
~~~

注意在这里我们使用数组存储可变事实, 既定事实和目标. 

我们首先对 **推断** 这一逻辑操作进行行为上的拆解. 任何推断都必须存在一个被推断主体, 也就是问题本身, 因此要对推断建模, 我们首先需要对问题本身进行建模. 

进一步地, 问题的本质是: 我们需要生成一个符合某些限制条件的策略, 使得问题中所提出的要求可以通过执行策略来满足. 显然地, 任何一个问题又可细分为四个部分: 
1. 当前已知, 但会随着我们采取行为而被改变的可变事实 (`Fluents`).
2. 当前已知, 且永不会被改变的既定事实 (`Permanents`).
3. 问题所提出的目标 (`Goal`).
4. 策略的组成部分: 我们可以执行的所有行为 (`Actions`).

我们下面限定 `Dalek` 的行为:

~~~
// Actions
carry(bookcase, study, sitting-room), 
go(sitting-room, hall)
~~~

显然更进一步地, 任何行为又包含四个部分:
1. 我们具体要执行的操作.
2. 该行为能够被执行所需要满足的前提条件.
3. 在行为执行后, 所出现的新事实.
4. 在行为执行后, 所消失的旧事实.

我们可以进一步地细化两个行为:

~~~
// carry
action-type(
    carry(Object, Room1, Room2),
    pre-conds([in(Object, Room1), 
               in(dalek, Room1), 
               adjacent(Room1, Room2)]),
    add-list([in(dalek, Room2), in(Object, Room2)]), 
    del-list([in(dalek, Room1), in(Object, Room1)]).
)

// go
action-type(
    go(Room1, Room2), 
    pre-conds([in(dalek, Room1), 
               adjacent(Room1, Room2)]),
    add-list([in(dalek, Room2)]), 
    del-list([in(dalek, Room1)]).
)
~~~

而通过将细化的行为描述中所有的变量赋值, 我们就可以将其 **实例化**. 

我们可以将所有可能采取的行策略表示为一个多叉树, 其中节点由一个表示当前状态的可变事实列表代表, 而每一条边都是一个 **被实例化的** 行为. 每个节点对应的子树数量为在该节点上可采取的行为的种数, 而每层节点的数量为上一整层节点在进行所有可能的行为后所能被变换到的新状态的数量总和.

在完成对问题的建模后, 我们还需要对应的逻辑方法用于解决问题并给出可行解. 称程序用于在所有可能的推断中选择用于解决问题达成目标的特定推断的算法为 **启发算法** (`Heuristics`).

启发算法的基础基于以 **亚里士多德三段论** 为代表的逻辑推导规则. 该部分内容在 `逻辑学` 相关笔记中已有提及, 故此处不再赘述. 由于我们同样可以使用逻辑推导规则对已知事实的状态进行转换, 因此我们也可以将转换过程建模为上文提到的状态树. 而算法给出可行解的过程, 也就可以被相应地视为在状态树上搜索的过程.

<br>

## 2. 搜索算法

在本节中, 我们介绍四种基础的搜索算法.

## 1. 深度优先搜索 `DFS`

深度优先搜索的原理是, 搜索到某个节点后, 若它不为所需要的节点, 则下一步总是以搜索它的子节点而非同级节点为最高优先. 该原理决定了其行为是: 一条条地纵向遍历, 从上到下地 **完整** 搜索每一条可行路径, 直到得到一个可行路径 (可行解) 为止. 其伪代码如下:

~~~Python
dfs(Queue):
    if Queue is non-empty:
        FirstNode := Queue.pop()
        if FirstNode is goal_node:
            return FirstNode
        add_daughters_of_FirstNode_to_the_front_of_the_queue
        return dfs(Queue)
    return failure
~~~

我们也可以这样递归地实现 `DFS`:

~~~Python
dfs(Node):
    if Node is goal_node:
        return Node
    for each Daughter in daughters_of_Node:
        if dfs(Daughter) != failure:
            return dfs(Daughter)
    return failure
~~~

<br>

## 2. 广度优先搜索 `BFS`

广度优先的原理是, 搜索到某个节点时, 若它不为所需要的节点, 则下一步总是以搜索与其同级的节点而非其子节点为最高优先. 故其行为是: 一级级地横向遍历, 从左到右地 **完整** 搜索每一级上的全部节点, 直到得到一个可行路径 (可行解) 为止. 其伪代码如下:

~~~Python
bfs(Queue):
    if Queue is non-empty:
        FirstNode := Queue.pop()
        if FirstNode is goal_node:
            return FirstNode
        add_daughters_of_FirstNode_to_the_end_of_the_queue
        return bfs(Queue)
    return failure
~~~

<br>

深度优先和广度优先搜索仍然属于结构最为简易的搜索方法, 它们给出的解可能并非解空间中的最优解. 

为了分别解与解之间的优劣, 我们引入 **代价** 的概念, 它刻画了一个人为定义的, 反映实际情况中为了实现某个解所需要付出的成本的大小. 为了找到 **成本最低** 的解, 我们进行如下假设:

1. 假定我们可能采取的任何行为都有一个 (!非负的) 成本 (`Cost`). 因此, 每个节点 $\nu$ 对应地有一个数据 $C(\nu)$ 表示从根节点执行一系列行为后到达该点所需要付出的成本 `Cost so-far`.

2. 假设对任何问题而言, 为了实现目标所需要付出的代价都是有限的, 因此存在一个非负的 **成本下界** (`lower bound`). 结合假设 `1`, 我们可知每个节点 $\nu$ 都有一个对应的 **从该状态转移到问题可满足状态所需要付出的代价的最小估计** `U(\nu)`.

我们下面介绍两种可用于求解成本最低解的算法: 分支定界算法 (`branch-and-bound`) 和 `A*`:

<br>

## 3. 分支定界算法 `Branch and Bound`

我们定义总代价 $K(\nu)$:

$$K(\nu) := C(\nu) + U(\nu)$$

根据上述分析, 此式显然成立. 在算法执行之初, $K(\nu)$ 是未知的. 当算法找到第一个解时, 其代价 $C(\nu)$ 被自然地赋值为 $K(\nu)$, 因为 $U(\nu)=0$, 此式我们记录下该解并对 $K(\nu)$ 赋值. 随着算法继续执行搜索, 我们可能找到更多的解. 若某个解的 $K(\mu) \leqslant K(nu)$, 我们更新最优解和相应的 $K(\nu)$. 在确定筛选完了所有解后, 此时的 $\nu$ 就是所需的最优解. 

在实际的分支定界算法中, 为了提高算法效率我们还会对搜索树进行剪枝. 

分支定界算法始终围绕状态树进行. 将原问题视为根节点并从从这里出发, 分支的含义就是将大的问题分割成小的问题. 大问题可以看成是搜索树的父节点, 故从大问题分割出来的小问题就是子节点, 分支就是不断增加子节点的过程. 

定界指在分支的过程中检查子问题的成本上下界. 若子问题不能产生更优解, 则对这一支执行剪枝. 直到所有子问题都不能产生一个更优的解时, 算法结束.

分支定界算法的伪代码如下:

~~~python
bnb(Queue, BestCost):
    if Queue is non-empty:
        FirstNode := Queue.pop()
        if K(FirstNode) < BestCost:
            if K(FirstNode) is_a_goal_node:
                CurrentBest := FirstNode
                BestCost := K(Currentbest)
            else
                add_daughters_of_FirstNode_to_the_front_of_Queue
        bnb(Queue, BestCost)
    else if BestCost != INFINITY:
        return CurrentBest
    return failure
~~~

<br>

## 4. A* 算法

在上学期的 `Java Coursework` 中, 我们已经部分地了解了 `A*` 算法. 在此处我们将介绍的 `A*` 算法的具体特征与之有所不同. 我们首先定义 A* 算法:

广义上的 `A*` 算法具备有两个部分组成的损失计算函数:
1. 从初始节点到当前节点所需要付出的代价. 
2. 从当前节点到目标节点所需要付出的代价. 

我们的目标为计算出总成本最小的解. 要实现这一目标, 我们可以通过优先选择在每一步中成本 $C(\nu)$ 最小的节点 $\nu$, 也就是 **优先选择局部最优**. 

`A*` 算法的伪代码如下:

~~~python
ast(Queue):
    if Queue is non-empty:
        FirstNode := Queue.pop()
        if FirstNode == GoalNode:
            return FirstNode
        compute daughters of FirstNode, then add to Queue
        order Queue by K
        return ast(Queue)
    return failure
~~~
